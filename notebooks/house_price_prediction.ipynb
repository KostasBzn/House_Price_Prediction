{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "houses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index is in the columnd so he have to remove it from the data we a re training\n",
    "houses_df = houses_df.set_index('Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y creation\n",
    "X = houses_df.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "\n",
    "# data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric and categoric pipe\n",
    "X_cat_columns = X.select_dtypes(exclude=\"number\").columns\n",
    "X_num_columns = X.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH ORDINAL ENCODING\n",
    "\n",
    "kitchen_qual = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n",
    "fireplace_qu = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']\n",
    "HeatingQC = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n",
    "GarageQual = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']\n",
    "\n",
    "categories = [\n",
    "    kitchen_qual,\n",
    "    fireplace_qu,\n",
    "    HeatingQC,\n",
    "    GarageQual,\n",
    "]\n",
    "\n",
    "ord_features = [\n",
    "    'KitchenQual',\n",
    "    'FireplaceQu',\n",
    "    'HeatingQC',\n",
    "    'GarageQual'\n",
    "]\n",
    "\n",
    "\n",
    "ord_encoder = OrdinalEncoder(categories=categories)\n",
    "\n",
    "oh_features = list(set(X_cat_columns) - set(ord_features))\n",
    "\n",
    "oh_encoder = OneHotEncoder(handle_unknown='ignore',\n",
    "                           sparse_output=False,\n",
    "                           min_frequency=0.03)\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "cat_encoder = ColumnTransformer(transformers=[\n",
    "    ('oh_encoder', oh_encoder, oh_features),\n",
    "    ('ord_encoder', ord_encoder, ord_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numerical pipeline with SimpleImputer\n",
    "numeric_pipe = make_pipeline(SimpleImputer(strategy=\"median\"))\n",
    "\n",
    "# Create categorical pipeline with SimpleImputer\n",
    "categoric_pipe = make_pipeline(cat_imputer, cat_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pipelines\n",
    "preprocessor = make_column_transformer((numeric_pipe, X_num_columns),\n",
    "                                       (categoric_pipe, X_cat_columns))\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    StandardScaler(),\n",
    "    GradientBoostingRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True) \n",
    "\n",
    "gb_param_grid = {\n",
    "    \"columntransformer__pipeline-1__simpleimputer__strategy\": [\"mean\"],  # Imputer strategy: using mean for missing values.\n",
    "    \"gradientboostingregressor__n_estimators\": [700],  # Number of trees (more trees may reduce variance but increase computation time) 100 - 500\n",
    "    \"gradientboostingregressor__max_depth\": [4],  # Max depth of the trees (higher depth increases model complexity, risking overfitting) 2 - 3\n",
    "    \"gradientboostingregressor__learning_rate\": [0.05, 0.1],  # The step size at each iteration (lower values may require more trees). 0.01 - Max 0.3\n",
    "    \"gradientboostingregressor__min_samples_split\": [2, 3],  # Minimum samples required to split an internal node 2 - 5\n",
    "    \"gradientboostingregressor__min_samples_leaf\": [3, 4],  # Minimum samples required to be at a leaf node 1 - 5\n",
    "    \"gradientboostingregressor__subsample\": [0.8, 1.0],  # Fraction of samples used for fitting each tree (use 1.0 for no subsample) 0.8,, 1.0\n",
    "    \"gradientboostingregressor__max_features\": ['sqrt', 0.5],  # The number of features to consider for each split 'sqrt', 0.5\n",
    "    \"gradientboostingregressor__n_iter_no_change\": [5, 10],  # Stop training if the validation score does not improve after 5 or 10 iterations 5, 10\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "gb_search = GridSearchCV(gb_pipeline, gb_param_grid, cv=kf, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {gb_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {gb_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training\n",
    "y_pred_train = gb_search.predict(X_train) \n",
    "# Calculate errors\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_rmse = root_mean_squared_error (y_train, y_pred_train)\n",
    "train_mape = mean_absolute_percentage_error(y_true = y_train,\n",
    "                                           y_pred = y_pred_train)\n",
    "train_r2 = r2_score(y_true = y_train,\n",
    "                   y_pred = y_pred_train)\n",
    "\n",
    "print(f\"Train MAE: {round(train_mae, 3)}\")\n",
    "print(f\"Train RMSE: {round(train_rmse, 3)}\")\n",
    "print(f\"Train MAPE: {round(train_mape, 3)}\")\n",
    "print(f\"Train R2: {round(train_r2, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test data\n",
    "y_pred_test = gb_search.predict(X_test)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_rmse = root_mean_squared_error (y_test, y_pred_test)\n",
    "test_mape = mean_absolute_percentage_error(y_true = y_test,\n",
    "                                           y_pred = y_pred_test)\n",
    "test_r2 = r2_score(y_true = y_test,\n",
    "                   y_pred = y_pred_test)\n",
    "\n",
    "print(f\"Test MAE: {round(test_mae, 3)}\")\n",
    "print(f\"Test RMSE: {round(test_rmse, 3)}\")\n",
    "print(f\"Test MAPE: {round(test_mape, 3)}\")\n",
    "print(f\"Test R2: {round(test_r2, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gb_search.best_estimator_\n",
    "best_model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
